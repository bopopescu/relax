 

 \newpage 

 \subsection{minimise\index{minimisation|textbf}} 

  
 \subsubsection{Synopsis} 

 Minimisation\index{minimisation} function. 
  

  
 \subsubsection{Defaults} 

 \textsf{\textbf{minimise}(self, *args, **keywords)} 

  
 \subsubsection{Arguments} 

 The arguments, which should all be strings, specify the minimiser\index{minimisation} as well as its options.  A minimum of one argument is required.  As this calls the function \quotecmd{generic\_minimise} the full list of allowed arguments is shown below in the reproduced \quotecmd{generic\_minimise} docstring. Ignore all sections except those labelled as minimisation\index{minimisation} algorithms and minimisation\index{minimisation} options.  Also do not select the Method\index{minimisation techniques!Method of Multipliers} of Multipliers constraint\index{constraint} algorithm as this is used in combination with the given minimisation\index{minimisation} algorithm if the keyword argument \quotecmd{constraints} is set to 1.  The grid search algorithm should also not be selected as this is accessed using the \quotecmd{grid} function instead.  The first argument passed will be set to the minimisation\index{minimisation} algorithm while all other arguments will be set to the minimisation\index{minimisation} options. 
  

 Keyword arguments differ from normal arguments having the form \quotecmd{keyword = value}.  All arguments must precede keyword arguments in python.\index{Python}  For more information see the examples section below or the python\index{Python} tutorial. 
  

  
 \subsubsection{Keyword Arguments} 

 \keyword{run:}  The name of the run.   

 \keyword{ func\_tol:}  The function tolerance.  This is used to terminate minimisation\index{minimisation} once the function value between iterations is less than the tolerance.  The default value is 1e-25.   

 \keyword{ grad\_tol:}  The gradient tolerance.  Minimisation\index{minimisation} is terminated if the current gradient value is less than the tolerance.  The default value is None.   

 \keyword{ max\_iterations:}  The maximum number of iterations.  The default value is 1e7.   

 \keyword{ constraints:}\index{constraint}  A flag specifying whether the parameters should be constrained.  The default is to turn constraints\index{constraint} on (constraints=1).   

 \keyword{ scaling:}  The diagonal scaling flag.  The default that scaling is on (scaling=1).  

  

 \keyword{print\_flag:}  The amount of information to print to screen.  Zero corresponds to minimal output while higher values increase the amount of output.  The default value is 1.  

  

  
 \subsubsection{Diagonal scaling} 

 Diagonal scaling is the transformation of parameter values such that each value has a similar order of magnitude.  Certain minimisation\index{minimisation} techniques, for example the trust region methods, perform extremely poorly with badly scaled problems.  In addition, methods which are insensitive to scaling such as Newton\index{minimisation techniques!Newton} minimisation\index{minimisation} may still benefit due to the minimisation\index{minimisation} of round off errors. 
  

 In Model-free analysis for example, if $S^2$ = 0.5, $\tau_e$ = 200 ps, and $R_{ex}$ = 15 1/s at 600 MHz, the unscaled parameter vector would be [0.5, 2.0e-10, 1.055e-18].  $R_{ex}$ is divided by (2 * $\pi$ * 600,000,000)**2 to make it field strength independent.  The scaling vector for this model may be something like [1.0, 1e-9, 1/(2 * $\pi$ * 6e8)**2].  By dividing the unscaled parameter vector by the scaling vector the scaled parameter vector is [0.5, 0.2, 15.0].  To revert to the original unscaled parameter vector, the scaled parameter vector and scaling vector are multiplied. 
  

  
 \subsubsection{Examples} 

 To minimise\index{minimisation} the model-free run \quotecmd{m4} using Newton\index{minimisation techniques!Newton} minimisation\index{minimisation} together with the GMW81 Hessian modification algorithm, the More and Thuente line search algorithm, a function tolerance of 1e-25, no gradient tolerance, a maximum of 10,000,000 iterations, constraints\index{constraint} turned on to limit\index{parameter!limit} parameter values, and have normal printout, type any combination of: 
  

 \example{relax> minimise(`newton', run=`m4')} 

 \example{relax> minimise(`Newton', run=`m4')} 

 \example{relax> minimise(`newton', `gmw', run=`m4')} 

 \example{relax> minimise(`newton', `mt', run=`m4')} 

 \example{relax> minimise(`newton', `gmw', `mt', run=`m4')} 

 \example{relax> minimise(`newton', `mt', `gmw', run=`m4')} 

 \example{relax> minimise(`newton', run=`m4', func\_tol=1e-25)} 

 \example{relax> minimise(`newton', run=`m4', func\_tol=1e-25, grad\_tol=None)} 

 \example{relax> minimise(`newton', run=`m4', max\_iter=1e7)} 

 \example{relax> minimise(`newton', run=name, constraints=1, max\_iter=1e7)} 

 \example{relax> minimise(`newton', run=`m4', print\_flag=1)} 

 To minimise\index{minimisation} the model-free run \quotecmd{m5} using constrained Simplex\index{minimisation techniques!simplex} minimisation\index{minimisation} with a maximum of 5000 iterations, type: 
  

 \example{relax> minimise(`simplex', run=`m5', constraints=1, max\_iter=5000)} 

  
 \subsubsection{Note} 

 {\footnotesize \begin{verbatim} 
  
 All the text which follows is a reproduction of the docstring of the generic_minimise 
 function.  Only take note of the minimisation algorithms and minimisation options sections, 
 the other sections are not relevant for this function.  The Grid search and Method of 
 Multipliers algorithms CANNOT be selected as minimisation algorithms for this function. 
  
 The section entitled Keyword Arguments is also completely inaccessible therefore please 
 ignore that text. 
  
 \end{verbatim}} 

 Generic minimisation\index{minimisation} function. 
  

 This is a generic function which can be used to access all minimisers\index{minimisation} using the same set of function arguments.  These are the function tolerance value for convergence tests, the maximum number of iterations, a flag specifying which data structures should be returned, and a flag specifying the amount of detail to print to screen. 
  

  
 \subsubsection{Keyword Arguments} 

 \keyword{func:}  The function which returns the value.   

 \keyword{ dfunc:}  The function which returns the gradient.   

 \keyword{ d2func:}  The function which returns the Hessian.   

 \keyword{ args:}  The tuple of arguments to supply to the functions func, dfunc, and d2func.   

 \keyword{ x0:}  The vector of initial parameter value estimates (as an array).   

 \keyword{ min\_algor:}  A string specifying which minimisation\index{minimisation} technique to use.   

 \keyword{ min\_options:}  A tuple to pass to the minimisation\index{minimisation} function as the min\_options keyword.   

 \keyword{ func\_tol:}  The function tolerance value.  Once the function value between iterations decreases below this value, minimisation\index{minimisation} is terminated.   

 \keyword{ grad\_tol:}  The gradient tolerance value.   

 \keyword{ maxiter:}  The maximum number of iterations.   

 \keyword{ A:}  Linear constraint\index{constraint} matrix m*n (A.x $\ge$ $b$).   

 \keyword{ $b$:}  Linear constraint\index{constraint} scalar vector (A.x $\ge$ $b$).   

 \keyword{ $l$:}  Lower bound\index{parameter!bounds} constraint\index{constraint} vector ($l$ $\le$ $x$ $\le$ $u$).   

 \keyword{ $u$:}  Upper bound\index{parameter!bounds} constraint\index{constraint} vector ($l$ $\le$ $x$ $\le$ $u$).   

 \keyword{ c:}  User supplied constraint\index{constraint} function.   

 \keyword{ dc:}  User supplied constraint\index{constraint} gradient function.   

 \keyword{ d2c:}  User supplied constraint\index{constraint} Hessian function.   

 \keyword{ full\_output:}  A flag specifying which data structures should be returned.   

 \keyword{ print\_flag:}  A flag specifying how much information should be printed to standard output during minimisation.\index{minimisation}  0 means no output, 1 means minimal output, and values above 1 increase the amount of output printed.  

  

  
 \subsubsection{Minimisation\index{minimisation|textbf} output} 

 The following values of the \quotecmd{full\_output} flag will return, in tuple form, the following data 
  

 \begin{description} 
 \item[0 --]  \quotecmd{xk},  
 \item[1 --]  \quotecmd{(xk, fk, $k$, f\_count, g\_count, h\_count, warning)},  
 \end{description} 
  

 where the data names correspond to 
  

 \begin{description} 
 \item[\quotecmd{xk} --]      The array of minimised\index{minimisation} parameter values,  
 \item[\quotecmd{fk} --]      The minimised\index{minimisation} function value,  
 \item[\quotecmd{k} --]       The number of iterations,  
 \item[\quotecmd{f\_count} --] The number of function calls,  
 \item[\quotecmd{g\_count} --] The number of gradient calls,  
 \item[\quotecmd{h\_count} --] The number of Hessian calls,  
 \item[\quotecmd{warning} --] The warning string.  
 \end{description} 
  

  
 \subsubsection{Minimisation\index{minimisation|textbf} algorithms} 

 A minimisation\index{minimisation} function is selected if the minimisation\index{minimisation} algorithm argument, which should be a string, matches a certain pattern.  Because the python\index{Python} regular\index{regular expression} expression \quotecmd{match} statement is used, various strings can be supplied to select the same minimisation\index{minimisation} algorithm.  Below is a list of the minimisation\index{minimisation} algorithms available together with the corresponding patterns. 
  

 This is a short description of python\index{Python} regular\index{regular expression} expression, for more information, see the regular\index{regular expression} expression syntax section of the Python\index{Python} Library Reference.  Some of the regular\index{regular expression} expression syntax used in this function is: 
  

 \begin{description} 
 \item[\quotecmd{[]} --]  A sequence\index{sequence} or set of characters to match to a single character.  For example, \quotecmd{[Nn]ewton} will match both \quotecmd{Newton} and \quotecmd{newton}.  
 \item[\quotecmd{\^{}} --]  Match the start of the string.  
 \item[\quotecmd{\$} --]  Match the end of the string.  For example, \quotecmd{\^{}[Ll][Mm]\$} will match \quotecmd{lm} and \quotecmd{LM} but will not match if characters are placed either before or after these strings.  
 \end{description} 
  

 To select a minimisation\index{minimisation} algorithm, set the argument to a string which matches the given pattern. 
  

 Parameter initialisation methods: 
  

 \begin{center} 
 \begin{tabular}{ll} 
 \toprule 
  Minimisation\index{minimisation} algorithm & Patterns  \\ 
 \midrule 
  Grid search & \quotecmd{\^{}[Gg]rid}  \\
 \bottomrule 
 \end{tabular} 
 \end{center} 
  

 Unconstrained line search methods: 
  

 \begin{center} 
 \begin{tabular}{ll} 
 \toprule 
  Minimisation\index{minimisation} algorithm & Patterns  \\ 
 \midrule 
  Back-and-forth coordinate descent & \quotecmd{\^{}[Cc][Dd]\$} or \quotecmd{\^{}[Cc]oordinate[ \_-][Dd]escent\$}  \\
   &   \\
  Steepest\index{minimisation techniques!steepest descent} descent & \quotecmd{\^{}[Ss][Dd]\$} or \quotecmd{\^{}[Ss]teepest[ \_-][Dd]escent\$}  \\
   &   \\
  Quasi-Newton BFGS\index{minimisation techniques!BFGS} & \quotecmd{\^{}[Bb][Ff][Gg][Ss]\$}  \\
   &   \\
  Newton\index{minimisation techniques!Newton} & \quotecmd{\^{}[Nn]ewton\$}  \\
   &   \\
  Newton-CG\index{minimisation techniques!Newton}\index{minimisation techniques!Newton conjugate gradient} & \quotecmd{\^{}[Nn]ewton[ \_-][Cc][Gg]\$} or \quotecmd{\^{}[Nn][Cc][Gg]\$}  \\
 \bottomrule 
 \end{tabular} 
 \end{center} 
  

 Unconstrained trust-region methods: 
  

 \begin{center} 
 \begin{tabular}{ll} 
 \toprule 
  Minimisation\index{minimisation} algorithm & Patterns  \\ 
 \midrule 
  Cauchy\index{minimisation techniques!Cauchy point} point & \quotecmd{\^{}[Cc]auchy}  \\
   &   \\
  Dogleg\index{minimisation techniques!dogleg} & \quotecmd{\^{}[Dd]ogleg}  \\
   &   \\
  CG-Steihaug\index{minimisation techniques!CG-Steihaug} & \quotecmd{\^{}[Cc][Gg][-\_ ][Ss]teihaug} or \quotecmd{\^{}[Ss]teihaug}  \\
   &   \\
  Exact\index{minimisation techniques!exact trust region} trust region & \quotecmd{\^{}[Ee]xact}  \\
 \bottomrule 
 \end{tabular} 
 \end{center} 
  

 Unconstrained conjugate\index{minimisation techniques!conjugate gradient} gradient methods: 
  

 \begin{center} 
 \begin{tabular}{ll} 
 \toprule 
  Minimisation\index{minimisation} algorithm & Patterns  \\ 
 \midrule 
  Fletcher-Reeves\index{minimisation techniques!Fletcher-Reeves} & \quotecmd{\^{}[Ff][Rr]\$} or \quotecmd{\^{}[Ff]letcher[-\_ ][Rr]eeves\$}  \\
   &   \\
  Polak-Ribi\`ere\index{minimisation techniques!Polak-Ribiere@Polak-Ribi\`ere} & \quotecmd{\^{}[Pp][Rr]\$} or \quotecmd{\^{}[Pp]olak[-\_ ][Rr]ibiere\$}  \\
   &   \\
  Polak-Ribi\`ere\index{minimisation techniques!Polak-Ribiere@Polak-Ribi\`ere} + & \quotecmd{\^{}[Pp][Rr]$\backslash$+\$} or \quotecmd{\^{}[Pp]olak[-\_ ][Rr]ibiere$\backslash$+\$}  \\
   &   \\
  Hestenes-Stiefel\index{minimisation techniques!Hestenes-Stiefel} & \quotecmd{\^{}[Hh][Ss]\$} or \quotecmd{\^{}[Hh]estenes[-\_ ][Ss]tiefel\$}  \\
 \bottomrule 
 \end{tabular} 
 \end{center} 
  

 Miscellaneous unconstrained methods: 
  

 \begin{center} 
 \begin{tabular}{ll} 
 \toprule 
  Minimisation\index{minimisation} algorithm & Patterns  \\ 
 \midrule 
  Simplex\index{minimisation techniques!simplex} & \quotecmd{\^{}[Ss]implex\$}  \\
   &   \\
  Levenberg-Marquardt\index{minimisation techniques!Levenberg-Marquardt} & \quotecmd{\^{}[Ll][Mm]\$} or \quotecmd{\^{}[Ll]evenburg-[Mm]arquardt\$}  \\
 \bottomrule 
 \end{tabular} 
 \end{center} 
  

 Constrained methods: 
  

 \begin{center} 
 \begin{tabular}{ll} 
 \toprule 
  Minimisation\index{minimisation} algorithm & Patterns  \\ 
 \midrule 
  Method\index{minimisation techniques!Method of Multipliers} of Multipliers & \quotecmd{\^{}[Mm][Oo][Mm]\$} or \quotecmd{[Mm]ethod of [Mm]ultipliers\$}  \\
 \bottomrule 
 \end{tabular} 
 \end{center} 
  

  
 \subsubsection{Minimisation\index{minimisation|textbf} options} 

 The minimisation\index{minimisation} options can be given in any order. 
  

 Line search algorithms.  These are used in the line search methods and the conjugate\index{minimisation techniques!conjugate gradient} gradient methods.  The default is the Backtracking line search. 
  

 \begin{center} 
 \begin{tabular}{ll} 
 \toprule 
  Line search algorithm & Patterns  \\ 
 \midrule 
  Backtracking line search & \quotecmd{\^{}[Bb]ack}  \\
   &   \\
  Nocedal and Wright interpolation & \quotecmd{\^{}[Nn][Ww][Ii]} or  \\
  based line search & \quotecmd{\^{}[Nn]ocedal[ \_][Ww]right[ \_][Ii]nt}  \\
   &   \\
  Nocedal and Wright line search & \quotecmd{\^{}[Nn][Ww][Ww]} or  \\
  for the Wolfe conditions & \quotecmd{\^{}[Nn]ocedal[ \_][Ww]right[ \_][Ww]olfe}  \\
   &   \\
  More and Thuente line search & \quotecmd{\^{}[Mm][Tt]} or \quotecmd{\^{}[Mm]ore[ \_][Tt]huente\$}  \\
   &   \\
  No line search & \quotecmd{\^{}[Nn]one\$}  \\
 \bottomrule 
 \end{tabular} 
 \end{center} 
  

 Hessian modifications.  These are used in the Newton,\index{minimisation techniques!Newton} Dogleg,\index{minimisation techniques!dogleg} and Exact\index{minimisation techniques!exact trust region} trust region algorithms. 
  

 \begin{center} 
 \begin{tabular}{ll} 
 \toprule 
  Hessian modification & Patterns  \\ 
 \midrule 
  Unmodified Hessian & \quotecmd{[Nn]one}  \\
   &   \\
  Eigenvalue\index{eigenvalues} modification & \quotecmd{\^{}[Ee]igen}  \\
   &   \\
  Cholesky with added multiple of & \quotecmd{\^{}[Cc]hol}  \\
  the identity &   \\
   &   \\
  The Gill, Murray, and Wright & \quotecmd{\^{}[Gg][Mm][Ww]\$}  \\
  modified Cholesky algorithm &   \\
   &   \\
  The Schnabel and Eskow 1999 & \quotecmd{\^{}[Ss][Ee]99}  \\
  algorithm &   \\
 \bottomrule 
 \end{tabular} 
 \end{center} 
  

 Hessian type, these are used in a few of the trust region methods including the Dogleg\index{minimisation techniques!dogleg} and Exact\index{minimisation techniques!exact trust region} trust region algorithms.  In these cases, when the Hessian type is set to Newton,\index{minimisation techniques!Newton} a Hessian modification can also be supplied as above.  The default Hessian type is Newton,\index{minimisation techniques!Newton} and the default Hessian modification when Newton\index{minimisation techniques!Newton} is selected is the GMW algorithm. 
  

 \begin{center} 
 \begin{tabular}{ll} 
 \toprule 
  Hessian type & Patterns  \\ 
 \midrule 
  Quasi-Newton BFGS\index{minimisation techniques!BFGS} & \quotecmd{\^{}[Bb][Ff][Gg][Ss]\$}  \\
   &   \\
  Newton\index{minimisation techniques!Newton} & \quotecmd{\^{}[Nn]ewton\$}  \\
 \bottomrule 
 \end{tabular} 
 \end{center} 
  

 For Newton\index{minimisation techniques!Newton} minimisation,\index{minimisation} the default line search algorithm is the More and Thuente line search, while the default Hessian modification is the GMW algorithm. 
  

 